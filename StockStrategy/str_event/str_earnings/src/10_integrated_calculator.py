#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
éšæ®µ10ï¼šæ•´åˆè®Šæ•¸è¨ˆç®—å™¨ ğŸš€
ä¸€æ¬¡APIèª¿ç”¨ï¼ŒåŒæ™‚è¨ˆç®—å¤šå€‹è®Šæ•¸ï¼Œå¤§å¹…æå‡æ•ˆèƒ½ï¼

è¨ˆç®—å…§å®¹ï¼š
- Y: CAR (ç´¯ç©ç•°å¸¸å ±é…¬)
- X2: 20æ—¥ç´¯ç©é€±è½‰ç‡
- X3: 10æ—¥ç´¯ç©å ±é…¬ç‡
- X4: åå¤§è‚¡æ±æŒè‚¡è®ŠåŒ–ç‡
- X6: æ•£æˆ¶æŒè‚¡è®ŠåŒ–ç‡
- X7: å¸‚å€¼ï¼ˆå°æ•¸ï¼‰
- X8: B/Mæ¯”ç‡
- X9: ç”¢æ¥­ä»£ç¢¼

å„ªå‹¢ï¼š
âœ… æ¸›å°‘90%çš„APIèª¿ç”¨æ¬¡æ•¸
âœ… å…±äº«æ•¸æ“šå¿«å–
âœ… ä¸¦è¡Œè¨ˆç®—æ‰€æœ‰è®Šæ•¸
âœ… çµ±ä¸€éŒ¯èª¤è™•ç†
"""

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import os
import subprocess
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor, as_completed
import json


def get_project_root():
    """å–å¾—å°ˆæ¡ˆæ ¹ç›®éŒ„"""
    current = Path.cwd()
    if current.name == 'src':
        return current.parent
    return current

PROJECT_ROOT = get_project_root()


class IntegratedCalculator:
    """æ•´åˆè®Šæ•¸è¨ˆç®—å™¨ - ä¸€æ¬¡APIèª¿ç”¨è¨ˆç®—æ‰€æœ‰è®Šæ•¸"""

    def __init__(
        self,
        event_list_path=None,
        window_start=-3,
        window_end=5
    ):
        """
        åˆå§‹åŒ–æ•´åˆè¨ˆç®—å™¨

        Parameters:
        -----------
        event_list_path : str
            äº‹ä»¶åˆ—è¡¨æª”æ¡ˆè·¯å¾‘
        window_start : int
            CARçª—æœŸèµ·å§‹ï¼ˆé è¨­ï¼š-3ï¼‰
        window_end : int
            CARçª—æœŸçµæŸï¼ˆé è¨­ï¼š5ï¼‰
        """
        self.event_list_path = event_list_path or str(PROJECT_ROOT / 'data/processed/event_list.csv')
        self.events_df = None
        self.results = []
        
        # CARçª—æœŸåƒæ•¸
        self.window_start = window_start
        self.window_end = window_end
        
        # TEJå·¥å…·è·¯å¾‘
        self.tool_abetad1 = str(PROJECT_ROOT / 'tej_tool_TWN_ABETAD1.py')
        self.tool_aprcd1 = str(PROJECT_ROOT / 'tej_tool_TWN_APRCD1.py')
        self.tool_ashr1a = str(PROJECT_ROOT / 'tej_tool_TWN_ASHR1A.py')
        self.tool_aifina = str(PROJECT_ROOT / 'tej_tool_TWN_AIFINA.py')
        self.tool_aind = str(PROJECT_ROOT / 'tej_tool_TWN_AIND.py')
        
        # è¼¸å‡ºç›®éŒ„
        self.output_abetad1 = PROJECT_ROOT / 'output_abetad1'
        self.output_aprcd1 = PROJECT_ROOT / 'output_aprcd1'
        self.output_ashr1a = PROJECT_ROOT / 'output_ashr1a'
        
        for dir_path in [self.output_abetad1, self.output_aprcd1, self.output_ashr1a]:
            dir_path.mkdir(exist_ok=True)
        
        print(f"ğŸš€ æ•´åˆè¨ˆç®—å™¨åˆå§‹åŒ–å®Œæˆ")
        print(f"   CARçª—æœŸ: [{window_start}, {window_end}]")

    def load_events(self):
        """è¼‰å…¥äº‹ä»¶åˆ—è¡¨"""
        print(f"\nğŸ“‚ è¼‰å…¥äº‹ä»¶åˆ—è¡¨: {self.event_list_path}")
        self.events_df = pd.read_csv(self.event_list_path)
        self.events_df['mdate'] = pd.to_datetime(self.events_df['mdate'])
        print(f"   ç¸½å…± {len(self.events_df)} ç­†äº‹ä»¶")
        return self

    def fetch_all_data(self, coid, event_date):
        """
        ä¸€æ¬¡æ€§å–å¾—æ‰€æœ‰éœ€è¦çš„è³‡æ–™ï¼ˆæœ€å°åŒ–APIèª¿ç”¨ï¼‰
        
        Returns:
        --------
        dict : {
            'abetad1': DataFrame,  # Beta & å ±é…¬ç‡
            'aprcd1': DataFrame,   # æˆäº¤é‡
            'ashr1a': DataFrame,   # è‚¡æ±æŒè‚¡
            'aifina': dict,        # è²¡å‹™è³‡æ–™
            'aind': str            # ç”¢æ¥­ä»£ç¢¼
        }
        """
        data = {}
        
        # ğŸš€ å„ªåŒ–ï¼šä½¿ç”¨365å¤©å¿«å–è¦–çª—ï¼Œä¸€æ¬¡å–å¾—æ‰€æœ‰éœ€è¦çš„æ­·å²æ•¸æ“š
        buffer_days = 400  # å¤šç•™ä¸€é»bufferç¢ºä¿æœ‰è¶³å¤ äº¤æ˜“æ—¥
        start_date = (event_date - timedelta(days=buffer_days)).strftime('%Y-%m-%d')
        end_date = (event_date + timedelta(days=30)).strftime('%Y-%m-%d')  # å¤šå–ä¸€é»æœªä¾†æ•¸æ“š
        
        # 1. ABETAD1 - Beta & å ±é…¬ç‡ï¼ˆç”¨æ–¼CARå’ŒX3ï¼‰
        print(f"      ğŸ“¡ å–å¾— ABETAD1 æ•¸æ“š...")
        data['abetad1'] = self._fetch_abetad1(coid, start_date, end_date)
        
        # 2. APRCD1 - æˆäº¤é‡ï¼ˆç”¨æ–¼X2ï¼‰
        print(f"      ğŸ“¡ å–å¾— APRCD1 æ•¸æ“š...")
        data['aprcd1'] = self._fetch_aprcd1(coid, start_date, end_date)
        
        # 3. ASHR1A - è‚¡æ±æŒè‚¡ï¼ˆç”¨æ–¼X4å’ŒX6ï¼‰
        print(f"      ğŸ“¡ å–å¾— ASHR1A æ•¸æ“š...")
        data['ashr1a'] = self._fetch_ashr1a(coid, event_date)
        
        # 4. AIFINA - è²¡å‹™è³‡æ–™ï¼ˆç”¨æ–¼X7å’ŒX8ï¼‰
        print(f"      ğŸ“¡ å–å¾— AIFINA æ•¸æ“š...")
        data['aifina'] = self._fetch_aifina(coid, event_date)
        
        # 5. AIND - ç”¢æ¥­ä»£ç¢¼ï¼ˆç”¨æ–¼X9ï¼‰
        print(f"      ğŸ“¡ å–å¾— AIND æ•¸æ“š...")
        data['aind'] = self._fetch_aind(coid, event_date)
        
        return data

    def _fetch_abetad1(self, coid, start_date, end_date):
        """å–å¾— ABETAD1 æ•¸æ“šï¼ˆBeta & å ±é…¬ç‡ï¼‰"""
        try:
            # æª¢æŸ¥å¿«å–
            existing_files = list(self.output_abetad1.glob(f'ABETAD1_{coid}_*.csv'))
            
            use_cache = False
            if existing_files:
                latest_file = max(existing_files, key=os.path.getctime)
                try:
                    df = pd.read_csv(latest_file)
                    df['mdate'] = pd.to_datetime(df['mdate'])
                    
                    cache_start = df['mdate'].min()
                    cache_end = df['mdate'].max()
                    required_start = pd.Timestamp(start_date)
                    required_end = pd.Timestamp(end_date)
                    
                    if cache_start <= required_start and cache_end >= required_end:
                        use_cache = True
                        print(f"         âœ“ ä½¿ç”¨å¿«å–")
                        return df
                except:
                    pass
            
            if not use_cache:
                # èª¿ç”¨API
                cmd = [
                    'python3', self.tool_abetad1,
                    '--coid', coid,
                    '--start', start_date,
                    '--end', end_date
                ]
                subprocess.run(cmd, check=True, capture_output=True)
                
                # è®€å–çµæœ
                latest_file = max(self.output_abetad1.glob(f'ABETAD1_{coid}_*.csv'), 
                                 key=os.path.getctime)
                df = pd.read_csv(latest_file)
                df['mdate'] = pd.to_datetime(df['mdate'])
                print(f"         âœ“ APIèª¿ç”¨æˆåŠŸ")
                return df
                
        except Exception as e:
            print(f"         âœ— ABETAD1 å–å¾—å¤±æ•—: {e}")
            return None

    def _fetch_aprcd1(self, coid, start_date, end_date):
        """å–å¾— APRCD1 æ•¸æ“šï¼ˆæˆäº¤é‡ï¼‰"""
        try:
            # æª¢æŸ¥å¿«å–
            existing_files = list(self.output_aprcd1.glob(f'APRCD1_{coid}_*.csv'))
            
            use_cache = False
            if existing_files:
                latest_file = max(existing_files, key=os.path.getctime)
                try:
                    df = pd.read_csv(latest_file)
                    df['mdate'] = pd.to_datetime(df['mdate'])
                    
                    cache_start = df['mdate'].min()
                    cache_end = df['mdate'].max()
                    required_start = pd.Timestamp(start_date)
                    required_end = pd.Timestamp(end_date)
                    
                    if cache_start <= required_start and cache_end >= required_end:
                        use_cache = True
                        print(f"         âœ“ ä½¿ç”¨å¿«å–")
                        return df
                except:
                    pass
            
            if not use_cache:
                # èª¿ç”¨API
                cmd = [
                    'python3', self.tool_aprcd1,
                    '--coid', coid,
                    '--start', start_date,
                    '--end', end_date
                ]
                subprocess.run(cmd, check=True, capture_output=True)
                
                # è®€å–çµæœ
                latest_file = max(self.output_aprcd1.glob(f'APRCD1_{coid}_*.csv'), 
                                 key=os.path.getctime)
                df = pd.read_csv(latest_file)
                df['mdate'] = pd.to_datetime(df['mdate'])
                print(f"         âœ“ APIèª¿ç”¨æˆåŠŸ")
                return df
                
        except Exception as e:
            print(f"         âœ— APRCD1 å–å¾—å¤±æ•—: {e}")
            return None

    def _fetch_ashr1a(self, coid, event_date):
        """å–å¾— ASHR1A æ•¸æ“šï¼ˆè‚¡æ±æŒè‚¡ï¼‰"""
        try:
            # ASHR1A æ˜¯å­£åº¦æ•¸æ“šï¼Œå–äº‹ä»¶æ—¥å‰å¾Œå„ä¸€å­£
            start_date = (event_date - timedelta(days=180)).strftime('%Y-%m-%d')
            end_date = (event_date + timedelta(days=180)).strftime('%Y-%m-%d')
            
            # æª¢æŸ¥å¿«å–
            existing_files = list(self.output_ashr1a.glob(f'ASHR1A_{coid}_*.csv'))
            
            use_cache = False
            if existing_files:
                latest_file = max(existing_files, key=os.path.getctime)
                try:
                    df = pd.read_csv(latest_file)
                    df['mdate'] = pd.to_datetime(df['mdate'])
                    
                    # æª¢æŸ¥æ˜¯å¦åŒ…å«äº‹ä»¶æ—¥å‰å¾Œçš„å­£åº¦è³‡æ–™
                    if len(df) > 0:
                        use_cache = True
                        print(f"         âœ“ ä½¿ç”¨å¿«å–")
                        return df
                except:
                    pass
            
            if not use_cache:
                # èª¿ç”¨API
                cmd = [
                    'python3', self.tool_ashr1a,
                    '--coid', coid,
                    '--start', start_date,
                    '--end', end_date
                ]
                subprocess.run(cmd, check=True, capture_output=True)
                
                # è®€å–çµæœ
                latest_file = max(self.output_ashr1a.glob(f'ASHR1A_{coid}_*.csv'), 
                                 key=os.path.getctime)
                df = pd.read_csv(latest_file)
                df['mdate'] = pd.to_datetime(df['mdate'])
                print(f"         âœ“ APIèª¿ç”¨æˆåŠŸ")
                return df
                
        except Exception as e:
            print(f"         âœ— ASHR1A å–å¾—å¤±æ•—: {e}")
            return None

    def _fetch_aifina(self, coid, event_date):
        """å–å¾— AIFINA æ•¸æ“šï¼ˆè²¡å‹™è³‡æ–™ï¼‰"""
        try:
            # å–å¾—æœ€è¿‘çš„è²¡å‹™è³‡æ–™ï¼ˆäº‹ä»¶æ—¥å‰ä¸€å¹´ï¼‰
            start_date = (event_date - timedelta(days=730)).strftime('%Y-%m-%d')
            end_date = event_date.strftime('%Y-%m-%d')
            
            cmd = [
                'python3', self.tool_aifina,
                '--coid', coid,
                '--start', start_date,
                '--end', end_date
            ]
            result = subprocess.run(cmd, check=True, capture_output=True, text=True)
            
            # AIFINAè¿”å›JSONæ ¼å¼
            data = json.loads(result.stdout)
            print(f"         âœ“ APIèª¿ç”¨æˆåŠŸ")
            return data
            
        except Exception as e:
            print(f"         âœ— AIFINA å–å¾—å¤±æ•—: {e}")
            return None

    def _fetch_aind(self, coid, event_date):
        """å–å¾— AIND æ•¸æ“šï¼ˆç”¢æ¥­ä»£ç¢¼ï¼‰"""
        try:
            cmd = [
                'python3', self.tool_aind,
                '--coid', coid,
                '--date', event_date.strftime('%Y-%m-%d')
            ]
            result = subprocess.run(cmd, check=True, capture_output=True, text=True)
            
            # AINDè¿”å›ç”¢æ¥­ä»£ç¢¼å­—ä¸²
            ind_code = result.stdout.strip()
            print(f"         âœ“ ç”¢æ¥­ä»£ç¢¼: {ind_code}")
            return ind_code
            
        except Exception as e:
            print(f"         âœ— AIND å–å¾—å¤±æ•—: {e}")
            return None

    def calculate_all_variables(self, coid, event_date, data):
        """
        åŸºæ–¼å–å¾—çš„æ•¸æ“šï¼Œè¨ˆç®—æ‰€æœ‰è®Šæ•¸
        
        Parameters:
        -----------
        coid : str
            è‚¡ç¥¨ä»£è™Ÿ
        event_date : datetime
            äº‹ä»¶æ—¥æœŸ
        data : dict
            _fetch_all_data è¿”å›çš„æ•¸æ“šå­—å…¸
        
        Returns:
        --------
        dict : åŒ…å«æ‰€æœ‰è®Šæ•¸çš„å­—å…¸
        """
        result = {
            'coid': coid,
            'event_date': event_date.strftime('%Y-%m-%d'),
            'has_video': self.events_df[
                (self.events_df['coid'] == coid) & 
                (self.events_df['mdate'] == event_date)
            ]['has_video'].iloc[0] if 'has_video' in self.events_df.columns else None
        }
        
        # è¨ˆç®— Y (CAR)
        print(f"      ğŸ”¢ è¨ˆç®— CAR...")
        car_data = self._calculate_car(event_date, data['abetad1'])
        result.update(car_data)
        
        # è¨ˆç®— X2 (é€±è½‰ç‡)
        print(f"      ğŸ”¢ è¨ˆç®— X2 (é€±è½‰ç‡)...")
        x2_data = self._calculate_x2(event_date, data['aprcd1'])
        result.update(x2_data)
        
        # è¨ˆç®— X3 (å ±é…¬ç‡)
        print(f"      ğŸ”¢ è¨ˆç®— X3 (å ±é…¬ç‡)...")
        x3_data = self._calculate_x3(event_date, data['abetad1'])
        result.update(x3_data)
        
        # è¨ˆç®— X4 & X6 (æŒè‚¡è®ŠåŒ–)
        print(f"      ğŸ”¢ è¨ˆç®— X4 & X6 (æŒè‚¡è®ŠåŒ–)...")
        x4_x6_data = self._calculate_x4_x6(event_date, data['ashr1a'])
        result.update(x4_x6_data)
        
        # è¨ˆç®— X7 & X8 (è²¡å‹™è®Šæ•¸)
        print(f"      ğŸ”¢ è¨ˆç®— X7 & X8 (è²¡å‹™è®Šæ•¸)...")
        x7_x8_data = self._calculate_x7_x8(data['aifina'])
        result.update(x7_x8_data)
        
        # X9 (ç”¢æ¥­ä»£ç¢¼)
        result['x9_industry'] = data['aind']
        
        return result

    def _calculate_car(self, event_date, abetad1_df):
        """è¨ˆç®—CAR"""
        if abetad1_df is None or len(abetad1_df) == 0:
            return {'car': None, 'beta_1yr': None, 'beta_3yr': None, 'beta_shrunk': None}
        
        try:
            # å–å¾—æœ€æ–°çš„Betaå€¼
            latest_beta = abetad1_df.iloc[-1]
            beta_1yr = latest_beta.get('beta_1yr_mkt', None)
            beta_3yr = latest_beta.get('beta_3yr_mkt', None)
            
            # è²æ°ç¸®æ¸›
            if pd.notna(beta_1yr) and pd.notna(beta_3yr):
                beta_shrunk = 0.7 * beta_1yr + 0.3 * beta_3yr
            else:
                beta_shrunk = None
            
            # è¨ˆç®—CAR
            window_start_date = event_date + timedelta(days=self.window_start)
            window_end_date = event_date + timedelta(days=self.window_end)
            
            window_df = abetad1_df[
                (abetad1_df['mdate'] >= window_start_date) &
                (abetad1_df['mdate'] <= window_end_date)
            ].copy()
            
            if len(window_df) == 0 or beta_shrunk is None:
                return {
                    'car': None,
                    'beta_1yr': beta_1yr,
                    'beta_3yr': beta_3yr,
                    'beta_shrunk': beta_shrunk
                }
            
            # è¨ˆç®—ç•°å¸¸å ±é…¬
            window_df['ar'] = window_df['roi'] - beta_shrunk * window_df['wroi']
            car = window_df['ar'].sum()
            
            return {
                'car': car,
                'beta_1yr': beta_1yr,
                'beta_3yr': beta_3yr,
                'beta_shrunk': beta_shrunk,
                'ar_count': len(window_df)
            }
            
        except Exception as e:
            print(f"         âœ— CARè¨ˆç®—å¤±æ•—: {e}")
            return {'car': None, 'beta_1yr': None, 'beta_3yr': None, 'beta_shrunk': None}

    def _calculate_x2(self, event_date, aprcd1_df):
        """è¨ˆç®—X2 (20æ—¥ç´¯ç©é€±è½‰ç‡)"""
        if aprcd1_df is None or len(aprcd1_df) == 0:
            return {'x2_turnover_20d': None}
        
        try:
            # T-23 åˆ° T-4ï¼ˆ20å€‹äº¤æ˜“æ—¥ï¼‰
            window_start = event_date - timedelta(days=30)  # buffer
            window_end = event_date - timedelta(days=4)
            
            window_df = aprcd1_df[
                (aprcd1_df['mdate'] >= window_start) &
                (aprcd1_df['mdate'] <= window_end)
            ].copy()
            
            # è¨ˆç®—é€±è½‰ç‡
            if 'vol' in window_df.columns and 'shs' in window_df.columns:
                window_df['daily_turnover'] = window_df['vol'] / window_df['shs']
                window_df = window_df.dropna(subset=['daily_turnover'])
                
                # å–æœ€è¿‘20å€‹äº¤æ˜“æ—¥
                recent_20 = window_df.nlargest(20, 'mdate')
                
                if len(recent_20) >= 15:  # è‡³å°‘è¦æœ‰15å€‹äº¤æ˜“æ—¥
                    x2 = recent_20['daily_turnover'].sum()
                    return {'x2_turnover_20d': x2}
            
            return {'x2_turnover_20d': None}
            
        except Exception as e:
            print(f"         âœ— X2è¨ˆç®—å¤±æ•—: {e}")
            return {'x2_turnover_20d': None}

    def _calculate_x3(self, event_date, abetad1_df):
        """è¨ˆç®—X3 (10æ—¥ç´¯ç©å ±é…¬ç‡)"""
        if abetad1_df is None or len(abetad1_df) == 0:
            return {'x3_return_10d': None}
        
        try:
            # T-13 åˆ° T-4ï¼ˆ10å€‹äº¤æ˜“æ—¥ï¼‰
            window_start = event_date - timedelta(days=20)  # buffer
            window_end = event_date - timedelta(days=4)
            
            window_df = abetad1_df[
                (abetad1_df['mdate'] >= window_start) &
                (abetad1_df['mdate'] <= window_end)
            ].copy()
            
            if 'roi' in window_df.columns:
                window_df = window_df.dropna(subset=['roi'])
                
                # å–æœ€è¿‘10å€‹äº¤æ˜“æ—¥
                recent_10 = window_df.nlargest(10, 'mdate')
                
                if len(recent_10) >= 8:  # è‡³å°‘è¦æœ‰8å€‹äº¤æ˜“æ—¥
                    x3 = recent_10['roi'].sum()
                    return {'x3_return_10d': x3}
            
            return {'x3_return_10d': None}
            
        except Exception as e:
            print(f"         âœ— X3è¨ˆç®—å¤±æ•—: {e}")
            return {'x3_return_10d': None}

    def _calculate_x4_x6(self, event_date, ashr1a_df):
        """è¨ˆç®—X4 (åå¤§è‚¡æ±è®ŠåŒ–) å’Œ X6 (æ•£æˆ¶è®ŠåŒ–)"""
        if ashr1a_df is None or len(ashr1a_df) == 0:
            return {'x4_insider_change': None, 'x6_retail_change': None}
        
        try:
            # æ‰¾äº‹ä»¶æ—¥å‰å¾Œçš„å…©å€‹å­£åº¦è³‡æ–™
            ashr1a_df = ashr1a_df.sort_values('mdate')
            
            # äº‹ä»¶æ—¥å‰çš„æœ€è¿‘å­£åº¦
            before_event = ashr1a_df[ashr1a_df['mdate'] <= event_date]
            if len(before_event) == 0:
                return {'x4_insider_change': None, 'x6_retail_change': None}
            
            current_quarter = before_event.iloc[-1]
            
            # å‰ä¸€å­£
            if len(before_event) < 2:
                return {'x4_insider_change': None, 'x6_retail_change': None}
            
            previous_quarter = before_event.iloc[-2]
            
            # è¨ˆç®—è®ŠåŒ–ç‡
            x4 = None
            x6 = None
            
            if 'top10_holding' in current_quarter and 'top10_holding' in previous_quarter:
                if pd.notna(current_quarter['top10_holding']) and pd.notna(previous_quarter['top10_holding']):
                    if previous_quarter['top10_holding'] != 0:
                        x4 = (current_quarter['top10_holding'] - previous_quarter['top10_holding']) / previous_quarter['top10_holding']
            
            if 'retail_holding' in current_quarter and 'retail_holding' in previous_quarter:
                if pd.notna(current_quarter['retail_holding']) and pd.notna(previous_quarter['retail_holding']):
                    if previous_quarter['retail_holding'] != 0:
                        x6 = (current_quarter['retail_holding'] - previous_quarter['retail_holding']) / previous_quarter['retail_holding']
            
            return {'x4_insider_change': x4, 'x6_retail_change': x6}
            
        except Exception as e:
            print(f"         âœ— X4/X6è¨ˆç®—å¤±æ•—: {e}")
            return {'x4_insider_change': None, 'x6_retail_change': None}

    def _calculate_x7_x8(self, aifina_data):
        """è¨ˆç®—X7 (å¸‚å€¼å°æ•¸) å’Œ X8 (B/Mæ¯”ç‡)"""
        if aifina_data is None:
            return {'x7_log_market_cap': None, 'x8_book_to_market': None}
        
        try:
            # å¾AIFINAæ•¸æ“šæå–
            market_cap = aifina_data.get('market_cap', None)
            book_value = aifina_data.get('book_value', None)
            
            x7 = np.log(market_cap) if market_cap and market_cap > 0 else None
            x8 = (book_value / market_cap) if (book_value and market_cap and market_cap > 0) else None
            
            return {'x7_log_market_cap': x7, 'x8_book_to_market': x8}
            
        except Exception as e:
            print(f"         âœ— X7/X8è¨ˆç®—å¤±æ•—: {e}")
            return {'x7_log_market_cap': None, 'x8_book_to_market': None}

    def process_one_event(self, idx, row):
        """è™•ç†å–®ä¸€äº‹ä»¶ï¼ˆç”¨æ–¼ä¸¦è¡Œï¼‰"""
        coid = row['coid']
        event_date = row['mdate']
        
        print(f"\n   ğŸ“Š [{idx+1}] è™•ç†: {coid} @ {event_date.strftime('%Y-%m-%d')}")
        
        try:
            # 1. å–å¾—æ‰€æœ‰æ•¸æ“šï¼ˆæœ€å°åŒ–APIèª¿ç”¨ï¼‰
            data = self.fetch_all_data(coid, event_date)
            
            # 2. è¨ˆç®—æ‰€æœ‰è®Šæ•¸
            result = self.calculate_all_variables(coid, event_date, data)
            
            print(f"      âœ… å®Œæˆï¼CAR={result.get('car', 'N/A')}")
            return result
            
        except Exception as e:
            print(f"      âŒ å¤±æ•—: {e}")
            return None

    def process_events(self, sample_size=None, start_date=None, end_date=None, max_workers=4):
        """
        æ‰¹æ¬¡è™•ç†äº‹ä»¶ï¼ˆä¸¦è¡ŒåŸ·è¡Œï¼‰
        
        Parameters:
        -----------
        sample_size : int
            è™•ç†æ¨£æœ¬æ•¸é‡
        start_date : str
            äº‹ä»¶æ—¥æœŸèµ·å§‹ç¯„åœ
        end_date : str
            äº‹ä»¶æ—¥æœŸçµæŸç¯„åœ
        max_workers : int
            ä¸¦è¡ŒåŸ·è¡Œçš„å·¥ä½œæ•¸é‡ï¼ˆé è¨­ï¼š4ï¼‰
        """
        df = self.events_df.copy()
        
        # æ—¥æœŸç¯„åœç¯©é¸
        if start_date:
            df = df[df['mdate'] >= pd.Timestamp(start_date)]
        if end_date:
            df = df[df['mdate'] <= pd.Timestamp(end_date)]
        
        # æ¨£æœ¬æ•¸é‡é™åˆ¶
        if sample_size:
            df = df.head(sample_size)
        
        print(f"\nğŸš€ é–‹å§‹è™•ç† {len(df)} ç­†äº‹ä»¶ï¼ˆä¸¦è¡Œæ•¸ï¼š{max_workers}ï¼‰...")
        
        # ä¸¦è¡Œè™•ç†
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            futures = {
                executor.submit(self.process_one_event, idx, row): idx 
                for idx, row in df.iterrows()
            }
            
            for future in as_completed(futures):
                result = future.result()
                if result:
                    self.results.append(result)
        
        print(f"\nâœ… è™•ç†å®Œæˆï¼æˆåŠŸ: {len(self.results)}/{len(df)}")

    def save_results(self, output_path=None):
        """å„²å­˜æ•´åˆçµæœ"""
        if not output_path:
            output_path = PROJECT_ROOT / 'data/processed/integrated_results.csv'
        
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        df = pd.DataFrame(self.results)
        df.to_csv(output_path, index=False)
        
        print(f"\nğŸ’¾ çµæœå·²å„²å­˜è‡³: {output_path}")
        print(f"   ç¸½ç­†æ•¸: {len(df)}")
        
        # é¡¯ç¤ºè®Šæ•¸å®Œæ•´åº¦
        print("\nğŸ“Š è®Šæ•¸å®Œæ•´åº¦:")
        for col in df.columns:
            if col not in ['coid', 'event_date']:
                completeness = (df[col].notna().sum() / len(df)) * 100
                print(f"   {col}: {completeness:.1f}%")
        
        return str(output_path)


def main():
    """æ¸¬è©¦ä¸»ç¨‹å¼"""
    import argparse
    
    parser = argparse.ArgumentParser(description='æ•´åˆè®Šæ•¸è¨ˆç®—å™¨')
    parser.add_argument('--sample', type=int, default=10, help='è™•ç†æ¨£æœ¬æ•¸é‡')
    parser.add_argument('--workers', type=int, default=4, help='ä¸¦è¡Œå·¥ä½œæ•¸é‡')
    parser.add_argument('--start-date', type=str, default='2020-01-01')
    parser.add_argument('--end-date', type=str, default='2025-12-31')
    parser.add_argument('--window-start', type=int, default=-3)
    parser.add_argument('--window-end', type=int, default=5)
    
    args = parser.parse_args()
    
    calculator = IntegratedCalculator(
        window_start=args.window_start,
        window_end=args.window_end
    )
    
    calculator.load_events()
    calculator.process_events(
        sample_size=args.sample,
        start_date=args.start_date,
        end_date=args.end_date,
        max_workers=args.workers
    )
    calculator.save_results()


if __name__ == '__main__':
    main()

#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
éšæ®µ3ï¼šX2è¨ˆç®—ï¼ˆ20æ—¥ç´¯ç©é€±è½‰ç‡ï¼‰
è¨ˆç®—T-23åˆ°T-4çš„20å€‹äº¤æ˜“æ—¥ç´¯ç©é€±è½‰ç‡
ç¬¦åˆclaude.mdæ—¥é »äº‹ä»¶ç ”ç©¶æ³•æ¶æ§‹
"""

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import os
import subprocess
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor, as_completed


# æª¢æ¸¬å°ˆæ¡ˆæ ¹ç›®éŒ„
def get_project_root():
    """å–å¾—å°ˆæ¡ˆæ ¹ç›®éŒ„"""
    current = Path.cwd()
    if current.name == 'src':
        return current.parent
    return current

PROJECT_ROOT = get_project_root()


class TurnoverCalculator:
    """20æ—¥ç´¯ç©é€±è½‰ç‡è¨ˆç®—å™¨ï¼ˆX2è®Šæ•¸ï¼‰"""

    def __init__(
        self,
        event_list_path=None,
        car_data_path=None,
        tool_aprcd1=None
    ):
        """
        åˆå§‹åŒ–X2è¨ˆç®—å™¨

        Parameters:
        -----------
        event_list_path : str
            äº‹ä»¶åˆ—è¡¨æª”æ¡ˆè·¯å¾‘ï¼ˆå‚™ç”¨ï¼‰
        car_data_path : str
            CARè³‡æ–™æª”æ¡ˆè·¯å¾‘ï¼ˆå„ªå…ˆä½¿ç”¨ï¼‰
        tool_aprcd1 : str
            TEJæ—¥æˆäº¤è³‡æ–™å·¥å…·
        """
        self.event_list_path = event_list_path or (PROJECT_ROOT / 'data/processed/event_list.csv')
        self.car_data_path = car_data_path or (PROJECT_ROOT / 'data/processed/car_data.csv')
        self.tool_aprcd1 = tool_aprcd1 or str(PROJECT_ROOT / 'tej_tool_TWN_APRCD1.py')
        self.events_df = None
        self.x2_results = []

    def load_events(self):
        """
        è¼‰å…¥äº‹ä»¶åˆ—è¡¨ï¼Œå„ªå…ˆä½¿ç”¨ car_data.csvï¼ˆåªè™•ç†æˆåŠŸè¨ˆç®—CARçš„äº‹ä»¶ï¼‰
        å¦‚æœ car_data.csv ä¸å­˜åœ¨ï¼Œå‰‡ä½¿ç”¨ event_list.csv
        """
        if self.car_data_path.exists():
            print(f"å¾ CAR è³‡æ–™è¼‰å…¥äº‹ä»¶: {self.car_data_path}")
            self.events_df = pd.read_csv(self.car_data_path)
            # car_data.csv ä½¿ç”¨ event_date æ¬„ä½ï¼Œéœ€çµ±ä¸€ç‚º mdate
            if 'event_date' in self.events_df.columns:
                self.events_df['mdate'] = pd.to_datetime(self.events_df['event_date'])
            elif 'mdate' in self.events_df.columns:
                self.events_df['mdate'] = pd.to_datetime(self.events_df['mdate'])
            
            # åªä¿ç•™å¿…è¦æ¬„ä½
            self.events_df = self.events_df[['coid', 'mdate']].copy()
            print(f"è¼‰å…¥ {len(self.events_df)} ç­†æˆåŠŸè¨ˆç®—CARçš„äº‹ä»¶\n")
        else:
            print(f"CAR è³‡æ–™ä¸å­˜åœ¨ï¼Œå¾äº‹ä»¶åˆ—è¡¨è¼‰å…¥: {self.event_list_path}")
            self.events_df = pd.read_csv(self.event_list_path)
            self.events_df['mdate'] = pd.to_datetime(self.events_df['mdate'])
            print(f"ç¸½å…± {len(self.events_df)} ç­†äº‹ä»¶\n")
        
        return self

    def get_daily_turnover(self, coid, event_date):
        """
        å–å¾—æ—¥æˆäº¤è³‡æ–™ï¼ˆT-23åˆ°T-4ï¼Œå…±20å€‹äº¤æ˜“æ—¥ï¼‰

        Parameters:
        -----------
        coid : str
            è‚¡ç¥¨ä»£è™Ÿ
        event_date : datetime
            äº‹ä»¶æ—¥æœŸï¼ˆT=0ï¼‰

        Returns:
        --------
        pd.DataFrame : åŒ…å«æˆäº¤é‡èˆ‡æµé€šè‚¡æ•¸çš„DataFrame
        """
        try:
            # ğŸš€ å„ªåŒ–ï¼šä½¿ç”¨365å¤©å¿«å–è¦–çª—ï¼ˆæ¸›å°‘é‡è¤‡APIå‘¼å«ï¼‰
            start_date = (event_date - timedelta(days=365)).strftime('%Y-%m-%d')
            end_date = (event_date - timedelta(days=3)).strftime('%Y-%m-%d')

            # æª¢æŸ¥æ˜¯å¦å·²æœ‰ç¾æˆæª”æ¡ˆ
            output_dir = PROJECT_ROOT / 'output_aprcd1'
            output_dir.mkdir(exist_ok=True)
            existing_files = list(output_dir.glob(f'APRCD1_{coid}_*.csv'))

            # æª¢æŸ¥ cache æª”æ¡ˆæ˜¯å¦åŒ…å«è¶³å¤ çš„æ—¥æœŸç¯„åœ
            use_cache = False
            if existing_files:
                latest_file = max(existing_files, key=os.path.getctime)
                try:
                    df_check = pd.read_csv(latest_file)
                    if len(df_check) > 0 and 'mdate' in df_check.columns:
                        df_check['mdate'] = pd.to_datetime(df_check['mdate'])
                        cache_start = df_check['mdate'].min()
                        cache_end = df_check['mdate'].max()
                        required_start = pd.Timestamp(start_date)
                        required_end = pd.Timestamp(end_date)
                        
                        if cache_start <= required_start and cache_end >= required_end:
                            use_cache = True
                except:
                    use_cache = False

            if not use_cache:
                print(f"  [é€±è½‰ç‡] å‘¼å«TEJ API: {coid}")
                cmd = [
                    'python3', self.tool_aprcd1,
                    '--code', str(coid),
                    '--start', start_date,
                    '--end', end_date
                ]
                subprocess.run(cmd, capture_output=True, timeout=60)
                existing_files = list(output_dir.glob(f'APRCD1_{coid}_*.csv'))
            else:
                print(f"  [é€±è½‰ç‡] ä½¿ç”¨ç¾æœ‰æª”æ¡ˆ (æ¶µè“‹ç¯„åœå®Œæ•´)")

            if not existing_files:
                return None

            # è®€å–æ—¥æˆäº¤è³‡æ–™
            latest_file = max(existing_files, key=os.path.getctime)
            df = pd.read_csv(latest_file)
            
            # æª¢æŸ¥æª”æ¡ˆæ˜¯å¦ç‚ºç©º
            if len(df) == 0:
                print(f"  [é€±è½‰ç‡] è­¦å‘Šï¼šæª”æ¡ˆç‚ºç©º")
                return None
                
            df['mdate'] = pd.to_datetime(df['mdate'])

            return df

        except Exception as e:
            print(f"  [é€±è½‰ç‡] éŒ¯èª¤ï¼šç„¡æ³•å–å¾—{coid}çš„æˆäº¤è³‡æ–™")
            print(f"  [é€±è½‰ç‡] è©³ç´°éŒ¯èª¤: {str(e)}")
            return None

    def calculate_x2_for_event(self, coid, event_date):
        """
        è¨ˆç®—å–®ä¸€äº‹ä»¶çš„X2ï¼ˆ20æ—¥ç´¯ç©é€±è½‰ç‡ï¼‰

        æ ¹æ“šclaude.mdï¼š
        - X2 = Î£(æ—¥æˆäº¤é‡/æµé€šåœ¨å¤–è‚¡æ•¸) from T-23 to T-4
        - å…±20å€‹äº¤æ˜“æ—¥ï¼ˆæ³¨æ„ï¼šæ˜¯äº¤æ˜“æ—¥è€Œéæ—¥æ›†æ—¥ï¼‰
        - å–®ä½ï¼šç™¾åˆ†æ¯”

        Parameters:
        -----------
        coid : str
            è‚¡ç¥¨ä»£è™Ÿ
        event_date : datetime
            äº‹ä»¶æ—¥æœŸ

        Returns:
        --------
        dict : X2çµæœ
        """
        # å–å¾—æ—¥æˆäº¤è³‡æ–™
        turnover_df = self.get_daily_turnover(coid, event_date)
        if turnover_df is None or len(turnover_df) == 0:
            return None

        # æ’åºä¸¦å®šä½äº‹ä»¶æ—¥
        turnover_df = turnover_df.sort_values('mdate').reset_index(drop=True)

        # æ‰¾åˆ°äº‹ä»¶æ—¥æˆ–æœ€æ¥è¿‘çš„äº¤æ˜“æ—¥
        event_mask = turnover_df['mdate'] == event_date
        if event_mask.any():
            event_idx = turnover_df[event_mask].index[0]
        else:
            # å°‹æ‰¾æœ€æ¥è¿‘çš„äº¤æ˜“æ—¥
            turnover_df['date_diff'] = abs((turnover_df['mdate'] - event_date).dt.days)
            event_idx = turnover_df['date_diff'].idxmin()
            turnover_df = turnover_df.drop('date_diff', axis=1)

        # å®šä½æ™‚é–“çª—æœŸï¼ˆT-23åˆ°T-4ï¼Œå…±20å€‹äº¤æ˜“æ—¥ï¼‰
        # T-23åˆ°T-4: å¾event_idx-23åˆ°event_idx-4ï¼ˆå…±20å€‹äº¤æ˜“æ—¥ï¼‰
        window_start = max(0, event_idx - 23)
        window_end = max(0, event_idx - 3)  # T-4æ˜¯event_idx-4ï¼Œä½†ilocæ˜¯å·¦é–‰å³é–‹ï¼Œæ‰€ä»¥æ˜¯-3

        # å–å¾—çª—æœŸè³‡æ–™
        window_df = turnover_df.iloc[window_start:window_end].copy()

        # éœ€è¦è‡³å°‘15å€‹äº¤æ˜“æ—¥
        if len(window_df) < 15:
            print(f"  [X2] äº¤æ˜“æ—¥æ•¸ä¸è¶³: {len(window_df)} < 15")
            return None

        # è¨ˆç®—æ¯æ—¥é€±è½‰ç‡
        # APRCD1ç›´æ¥æä¾›turnoveræ¬„ä½ï¼ˆå·²æ˜¯å°æ•¸å½¢å¼ï¼Œä¾‹å¦‚0.0427ä»£è¡¨4.27%ï¼‰
        if 'turnover' in window_df.columns:
            # turnoverå·²ç¶“æ˜¯ratioå½¢å¼ï¼Œä¹˜ä»¥100è½‰ç‚ºç™¾åˆ†æ¯”
            window_df['daily_turnover'] = window_df['turnover'] * 100
        elif 'volume' in window_df.columns and 'outstanding' in window_df.columns:
            # å‚™ç”¨è¨ˆç®—ï¼šæˆäº¤é‡/æµé€šè‚¡æ•¸
            window_df['daily_turnover'] = (window_df['volume'] / window_df['outstanding']) * 100
        else:
            print(f"  [é€±è½‰ç‡] ç¼ºå°‘å¿…è¦æ¬„ä½ï¼Œå¯ç”¨æ¬„ä½: {list(window_df.columns)}")
            return None

        # è¨ˆç®—20æ—¥ç´¯ç©é€±è½‰ç‡
        x2_cumulative_turnover = window_df['daily_turnover'].sum()

        return {
            'coid': coid,
            'event_date': event_date,
            'X2_cumulative_turnover_20d': x2_cumulative_turnover,
            'n_days': len(window_df)
        }

    def process_events(self, sample_size=None, start_date='2020-01-01', end_date='2025-12-31'):
        """
        æ‰¹æ¬¡è™•ç†æ‰€æœ‰äº‹ä»¶

        Parameters:
        -----------
        sample_size : int, optional
            æ¨£æœ¬æ•¸é‡é™åˆ¶ï¼ˆç”¨æ–¼æ¸¬è©¦ï¼‰
        start_date : str
            äº‹ä»¶æ—¥æœŸèµ·å§‹ç¯„åœï¼ˆYYYY-MM-DDï¼‰
        end_date : str
            äº‹ä»¶æ—¥æœŸçµæŸç¯„åœï¼ˆYYYY-MM-DDï¼‰
        """
        print("="*80)
        print("é–‹å§‹è¨ˆç®—X2ï¼ˆ20æ—¥ç´¯ç©é€±è½‰ç‡ï¼‰")
        print("="*80)

        # ä½¿ç”¨åƒæ•¸åŒ–çš„æ—¥æœŸç¯„åœéæ¿¾
        start_ts = pd.Timestamp(start_date)
        end_ts = pd.Timestamp(end_date)
        
        events_filtered = self.events_df[
            (self.events_df['mdate'] >= start_ts) & 
            (self.events_df['mdate'] <= end_ts)
        ].copy()
        print(f"éæ¿¾è‡³ {start_date} ~ {end_date} äº‹ä»¶: {len(events_filtered)} ç­†\n")

        # çµ±ä¸€æ’åºï¼šå…ˆæŒ‰æ—¥æœŸã€å†æŒ‰è‚¡ç¥¨ä»£è™Ÿï¼ˆç¢ºä¿æ‰€æœ‰éšæ®µè™•ç†ç›¸åŒé †åºçš„äº‹ä»¶ï¼‰
        events_sorted = events_filtered.sort_values(['mdate', 'coid'], ascending=True)

        if sample_size:
            events_to_process = events_sorted.head(sample_size)
            print(f"è™•ç†æ¨£æœ¬æ•¸é‡: {len(events_to_process)}ï¼ˆå¾ {start_date} é–‹å§‹ï¼‰\n")
        else:
            events_to_process = events_sorted
            print(f"è™•ç†å…¨éƒ¨äº‹ä»¶: {len(events_to_process)} ç­†\n")

        total = len(events_to_process)

        # ğŸš€ ä½¿ç”¨å¤šç·šç¨‹ä¸¦è¡Œè™•ç†ï¼ˆåŠ é€Ÿ 3-5 å€ï¼‰
        max_workers = 6  # å¢åŠ åˆ° 8 å€‹ç·šç¨‹ä»¥æå‡é€Ÿåº¦
        print(f"ğŸš€ ä½¿ç”¨ {max_workers} å€‹ç·šç¨‹ä¸¦è¡Œè™•ç†\n")

        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            # æäº¤æ‰€æœ‰ä»»å‹™
            future_to_event = {}
            for idx, (_, row) in enumerate(events_to_process.iterrows(), 1):
                coid = row['coid']
                event_date = row['mdate']
                
                future = executor.submit(self.calculate_x2_for_event, coid, event_date)
                future_to_event[future] = (idx, coid, event_date)
            
            # æ”¶é›†çµæœï¼ˆæŒ‰å®Œæˆé †åºï¼‰
            completed = 0
            for future in as_completed(future_to_event):
                idx, coid, event_date = future_to_event[future]
                completed += 1
                
                try:
                    result = future.result()
                    if result:
                        self.x2_results.append(result)
                        print(f"âœ“ [{completed}/{total}] {coid} @ {event_date.strftime('%Y-%m-%d')} - X2: {result['X2_cumulative_turnover_20d']:.2f}%")
                    else:
                        print(f"âœ— [{completed}/{total}] {coid} @ {event_date.strftime('%Y-%m-%d')} - ç„¡æ³•è¨ˆç®—X2")
                except Exception as e:
                    print(f"âœ— [{completed}/{total}] {coid} @ {event_date.strftime('%Y-%m-%d')} - éŒ¯èª¤: {e}")

        print(f"\nå®Œæˆï¼æˆåŠŸè¨ˆç®— {len(self.x2_results)} ç­†äº‹ä»¶çš„ X2\n")

    def save_results(self, output_path=None):
        """å„²å­˜X2çµæœ"""
        output_path = output_path or (PROJECT_ROOT / 'data/processed/x2_turnover.csv')
        output_path = Path(output_path)
        output_path.parent.mkdir(parents=True, exist_ok=True)

        if not self.x2_results:
            print("è­¦å‘Šï¼šæ²’æœ‰X2çµæœå¯å„²å­˜")
            return

        df = pd.DataFrame(self.x2_results)
        df.to_csv(output_path, index=False)

        print(f"X2è³‡æ–™å·²å„²å­˜è‡³: {output_path}")
        print(f"å…± {len(df)} ç­†çµæœ\n")

        # æ‘˜è¦çµ±è¨ˆ
        print("=== X2æ‘˜è¦çµ±è¨ˆ ===\n")
        print(f"å¹³å‡: {df['X2_cumulative_turnover_20d'].mean():.2f}%")
        print(f"ä¸­ä½æ•¸: {df['X2_cumulative_turnover_20d'].median():.2f}%")
        print(f"æ¨™æº–å·®: {df['X2_cumulative_turnover_20d'].std():.2f}%")
        print(f"æœ€å°å€¼: {df['X2_cumulative_turnover_20d'].min():.2f}%")
        print(f"æœ€å¤§å€¼: {df['X2_cumulative_turnover_20d'].max():.2f}%")


def main():
    """ä¸»ç¨‹å¼"""
    print("="*80)
    print("éšæ®µ3ï¼šX2è¨ˆç®—ï¼ˆ20æ—¥ç´¯ç©é€±è½‰ç‡ï¼ŒT-23åˆ°T-4ï¼‰")
    print("="*80)
    print()

    calculator = TurnoverCalculator()
    calculator.load_events()
    calculator.process_events(sample_size=10)  # æ¸¬è©¦ï¼šå…ˆè™•ç†10ç­†
    calculator.save_results()

    print("éšæ®µ3å®Œæˆï¼\n")


if __name__ == '__main__':
    main()
